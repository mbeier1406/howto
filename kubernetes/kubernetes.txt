#
# Kubernetes
#

# Installationen
  - Rancher's next-generation Kubernetes rke2
  echo "Y3VybCAtc2ZMIGh0dHBzOi8vZ2V0LnJrZTIuaW8gfCBzaCAtCgogICAgc3lzdGVtY3RsIGVuYWJsZSAtLW5vdyBya2UyLXNlcnZlci5zZXJ2aWNlCgogICAgY3VybCAtTE8gaHR0cHM6Ly9kbC5rOHMuaW8vcmVsZWFzZS92MS4yMS4wL2Jpbi9saW51eC9hbWQ2NC9rdWJlY3RsCgogICAgY2htb2QgK3gga3ViZWN0bAoKICAgIG12IC9yb290L2t1YmVjdGwgL3Vzci9iaW4vCgogICAga3ViZWN0bCAtLWt1YmVjb25maWcgL2V0Yy9yYW5jaGVyL3JrZTIvcmtlMi55YW1sIGdldCBhbGwgLW4ga3ViZS1zeXN0ZW0KCiAgICBleHBvcnQgS1VCRUNPTkZJRz0vZXRjL3JhbmNoZXIvcmtlMi9ya2UyLnlhbWwKCiAgICBlY2hvICJQbGVhc2UgcnVuIHRoZSBmb2xsb3dpbmcgY29tbWFuZCBmb3IgY29ubmVjdGluZyB0byB0aGUgY2x1c3RlcjoiCgogICAgZWNobyAiZXhwb3J0IEtVQkVDT05GSUc9L2V0Yy9yYW5jaGVyL3JrZTIvcmtlMi55YW1sIg==" | base64 --decode | bash
  export KUBECONFIG=/etc/rancher/rke2/rke2.yaml
  - Lightweight Kubernetes: k3s
  curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=v1.24.4+k3s1 sh - # Installation und Start k3s
  export KUBECONFIG=/etc/rancher/k3s/k3s.yml # Client Konfigurationsdatei kubeconfig
  - Kubernetes mit Terminal UI: k9s
  # Installationsanleitung in https://github.com/derailed/k9s#installation
  curl -sS https://webinstall.dev/k9s | bash # Beispiel ueber Webinstall
  export PATH=/root/.local/bin:${PATH}
  k9s # :q fuer Ende
  k9s --kubeconfig ...yaml # Oder export KUBECONFIG=...

  # Cluster Administration, Startup Probes usw.
  kubectl get nodes # Pruefen, ob der Cluster laeuft

  # Imperative Kommandos
  kubectl run nginx-pod --image nginx:1.12.0 # Pod im default Namespace starten
  kubectl run <Podname> --image <Image> -- <Command> # spezielles Kommando im Pod ausfuehren
  kubectl get pods -ocustom-columns="NAME:.metadata.name,IMAGE:.spec.containers[0].image,NAMESPACE:.metadata.namespace" # bestimmte Spalten anzeigen
  kubectl create namespace localns; kubectl run redis --image redis:alpine --labels app=db --namespace localns --port 8080 # im eigenen Namespace
  kubectl create deployment web --image jcdemo/flaskapp --replicas 4 # Deployment mit vier Replicas
  kubectl run httpd --image httpd:alpine --port 80 --expose # Pod mit Service (Cluster IP)
  kubectl run ... --dry-run=client --output=<Format (yaml, json, ...)> > <Dateiname> # Pod-Definition als Datei speichern

  # Objekte
  # Kubernetesobjekte wie zB Pods (record of intend) mit Sepc/Status ueber den API-Server (zB ueber kubectl) pflegen:
  # - containerisierte Anwendungen auf den Nodes
  # - welche Ressourcen fuer sie zur Verfuegung stehen
  # - Richtlinien fuer Neustarte, Upgrades, Fehlertoleranz, ...
  # Objektbeschreibungen: https://kubernetes.io/docs/reference/kubernetes-api/
  # Objektinfos:
  # - Metadata
  # - Spec = desired state
  # - Status = aktueller Stand
  # Definition der drei: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md
  # * Pods
    kubectl apply --filename ngnix-pod.yaml # Pod anlegen
    kubectl describe pod ... # Infos zum Pod
    kubectl get pods # Pods anzeigen
    kubectl delete --filename ngnix-pod.yaml # Pod wieder loeschen
  # * Probes: laufen die Container?
  #   Die Restart-Policy betrifft immer den gesamten Pod! Bei Deployments/DeamonSets/StatefulSets immer "Always"
  #   - Liveness: "Lebt" der Container? Neustart des Containers bei Fehlern.
    kubectl apply --filename liveness-pod.yaml
  #   - Readiness: Verarbeitet der Container Anfragen? Keine weiteren werden dorthin delegiert bei Fehlern.
    kubectl apply --filename readiness-pod.yaml
  #   - Startup: Ist der Container bereits hochgefahren? Vorher keine Liveness/Readiness Proben
    kubectl apply --filename startupprobe-pod.yaml
  # * Deployments: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
  #   Managen ReplicaSets (automatischer Neustart usw.) = mehrere identische Pods:
  #   - Verschiedene Updatestrategien (rolling update usw.) und rollback zu aelterem Stand
  #   - Automatische Skalierung ueber Anzahl der Pods
  #   - Automatischer Neustart
    kubectl apply --filename nginx-deployment.yaml # Deployment anlegen, yaml-Date aendern erneut ausfuehren = Update
    kubectl get deployments
    watch kubectl get pods -o wide
  # * ReplicaSets
  #   Automatisch wird ein ReplicaSet mit angelegt
  #   Bei Updates bleibt ein Deployment, aber mehrere ReplicaSets (nicht-aktive mit 0 desired Pods!)
    kubectl get replicasets
  #   Skalierung: ReplicaSet aendern
    watch kubectl get pods # "desired state" des aktiven ReplicaSets anpassen
    kubectl scale deployment/nginx-deployment --replicas=...
    kubectl delete pod <Pod-Name>; watch kubectl get replicasets # wird wieder auf die spezifizierte Anzahl Pods geaendert
  # * Namespaces
  #   Fuer mulit-user Szenarios, Workloads trennen
  #   Produktion absichern: https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/
    kubectl create namespace ... # fuer einen privaten Workload
    kubectl get namespaces
    kubectl get pods --namespace=... # zB kube-system fuer interne Pods
    kubectl get pods --all-namspaces # alle Pods in allen Namespaces
  # * Logging
  #  Nur fuer Pods
    kubectl apply --filename counter-pod.yaml # Pod mit Ausgaben auf stdout
    kubectl logs counter --follow
  # Command execution (nur fuer Pods)
  kubectl exec --tty --stdin <Pod> -- <Kommando>

  # Resourcen
  # * Secrets
  #   Im Standard unverschluesselt im etcd gespeichert
  #   => Loesung: 1. Definition RBAC-Rolle 2. Zugriff auf spezielle Container einschraenken 3. externe Speicher
  #   Typen:
  #   - opaque: Allgemein fuer Text
  #   - docker-registry: Zugriff auf private Docker Registries
  #   - tls: private Schluessel und Zertifikate
  #   - ssh: private Schluessel, fingerprints
  #   - service-account-token: Zugriff auf Serviceaccounts ueber den API-Server
    kubectl create secret <Typ> <Name> <Daten>
    kubectl get secrets # Spalte DATA: Anzahl Eintraege
    kubectl get secret <Secret-Name> --output yaml
    kubectl describe secret <Secret-Name>
    # Opaque
    kubectl create secret generic geheim-opaque --from-literal=user=... --from-literal=pass=...
    # alternativ --from-file=<dir> oder kubectl apply --filename opaque-secret.yaml
    kubectl apply --filename pod-opaque-secret.yaml # Testen...
    kubectl exec --tty --stdin pod-opaque-secret -- /bin/bash
    $ echo $user $pass
    # TLS
    openssl req -x509 -newkey rsa:4096 -nodes -keyout tls.key -out tls.crt -subj "/CN=golkonda.de" # Key und Zertifikat
    kubectl create secret tls geheim-tls --cert=tls.crt --key=tls.key # Test analog Opaque
    # docker-registry: wird auf dem Node fuer das Kubelet zur Anmeldung an der Image-Registry benoetigt
    kubectl create secret docker-registry geheim-dockerregistry  \
    --docker-server=DOCKER_REGISTRY_SERVER \
    --docker-username=DOCKER_USER \
    --docker-password=DOCKER_PASSWORD \
    --docker-email=DOCKER_EMAIL
    kubectl apply --filename pod-dockerregistry-secret.yaml # laedt das Image von der zuvor definierten Registry
    # Da Secrets von jedem API/etcd-User, Pod, Deployment, ... ausgelesen werden koennen, externer Speicher mit mehr Sicherheit:
    # - https://www.vaultproject.io/docs/
    # - https://aws.amazon.com/secrets-manager/
  # * ConfigMaps
  #   Konfigurationsvariablen fuer Pods bereitstellen
    kubectl get configmap <Name> # aus metadata/name
    kubectl describe configmap <Name>
    # Bereitstellen als Umgebungsvariablen => werden bei Updates NICHT automatisch aktualisiert
    kubectl apply --filename=config-map.yaml
    kubectl apply --filename=config-map-pod.yaml
    # Bereitstellen als  Konfigurationsdateien => werden bei Updates automatisch aktualisiert
    kubectl apply --filename=config-map-file.yaml
    kubectl apply --filename=config-map-file-pod.yaml
  # * Service
  #   https://kubernetes.io/docs/concepts/services-networking/service/: Anwendung im Cluster bekannt machen
    kubectl apply --filename deployment-mongodb.yaml # Beispiel MongoDB mit Gaestebuch
    kubectl apply --filename service-mongodb.yaml
    kubectl apply --filename deployment-guestbook.yaml
    kubectl apply --filename deployment-guestbook.yaml
    kubectl get service frontend
    curl http://localhost:30080
  # * Ingress
  #    https://kubernetes.io/docs/concepts/services-networking/ingress/: Anwendungen veroeffentlichen ueber Reverse Proxy
  #    Alternative zum Service mit NodePort
    kubectl apply --filename ingress-guestbook.yaml
    kubectl get ingress
    curl http://localhost:80
  # * PersistentVolume
  #   Anforderung (PVC): https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims
  #   Manuell bereitgestellt (PV): https://kubernetes.io/docs/concepts/storage/persistent-volumes/
  #   Automatisch ueber StorageClass: https://kubernetes.io/docs/concepts/storage/storage-classes
  #   Unabhaengig von Pods, Daten "ueberleben" auch deren Loeschung
    kubectl apply --filename pvc.yaml # Anforderung des Volumes mit Namen PVC-NAME
    kubectl apply --filename pv.yaml # Verwnedung des Volumes mit Namen PVC-NAME
    kubectl get/describe pv/pvc

  # Jobs/CronJobs
  # Jobs: ein oder mehrere Pods starten und Erolg sicherstellen: fuer kurze Prozesse/Batch
  # CronJob: Jobs mit Zeitsteuerung
  kubectl apply -f job-busybox.yaml
  kubectl get jobs
  kubectl describe job <Jobname> # hier: busybox-job
  kubectl get pods -ljob-name=<Jobname>
  kubectl logs -ljob-name=<Jobname>
  kubectl apply -f cronjob-busybox.yaml
  kubectl get cronjobs
  kubectl describe cronjob <Cronjobname> # hier: busybox-cronjob
  watch kubectl get pods --selector=job-name=<Cronjobname>

  # Static Pods
  # Statische Pods (an einen Knoten gebunden) sind vom CONTROLLER-Typ Node und werden direkt vom kubelet (nicht API-Server) verwaltet
  # Ablegen der yaml-Datei im Manifest-Verzeichnis (Kublet Konfiguration) des Knotens
  # Beispiel static-pod-manifest.yaml
  kubectl get pods --all-namespaces --output custom-columns="NAME:.metadata.name,CONTROLLER:.metadata.ownerReferences[].kind"

  # Application Logging

  # DaemonSets
    kubectl get daemonsets -A

  # Helm
  curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash # Installation

